{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expense classification using Wordvectors\n",
    "This file explains a methodology of expense classification using pretrained Wordvectors. This example uses two pretrained vectors, they are\n",
    "\n",
    "* fast text (https://s3-us-west-1.amazonaws.com/fasttext-vectors/wiki-news-300d-1M.vec.zip)\n",
    "\n",
    "* Glove (http://nlp.stanford.edu/data/glove.6B.zip)\n",
    "\n",
    "\n",
    "## Algorithm Description\n",
    "\n",
    "### Required Downloads & Installations\n",
    "* Download the Wordvectors from above link, unzip in a folder of choice\n",
    "* Download and install gensim and sklearn\n",
    "### Algorithm\n",
    "* Load the Wordvectors\n",
    "* Read the training and the validation datafiles, extract target classes and predictors\n",
    "    * For this example we are considering the **expense category** as target class and **expense description** as predictor\n",
    "* Pass the expense description as input to feature engineering utility and get the sentence vectors\n",
    "    * Feature engineering utility is in Data_Prep_Utils.py\n",
    "    * It takes sentence list and the Wordvector models as inputs, returns sentence vectors as outputs\n",
    "* Pass the training data sentence vector and target class to the Train_Model utility in ML_Utils.py\n",
    "    * Train_Model currently implements a random forest with default settings. Returns trained model and the hold out data\n",
    "* Validate the model by publishing the prediction probability, F1 score and comparison against the actual classes\n",
    "### Assumptions\n",
    "* All columns will have data - hence missing data treatment is not performed\n",
    "* The files provided for algorithm will have the same format, hence will have **expense category** and **expense description** columns\n",
    "\n",
    "## How to Run Algorithm for other files\n",
    "Go to the fourth executable code cell and change the path of training and the validation files\n",
    "\n",
    "Training_Sentences, Training_Labels = DPU.Get_Data(**'Your Training file path/Training_filename.csv'**)\n",
    "\n",
    "Validation_Sentances, Validation_Labels = DPU.Get_Data(**'Your validataion file path/validation_filename.csv'**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Relavent Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunda\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "C:\\Users\\sunda\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import KeyedVectors\n",
    "# Load Pretrained Glove Model\n",
    "import DF_Clean_Up as Clean_Up\n",
    "import Data_Prep_Utils as DPU\n",
    "import Text_Proc_Utils as TPU\n",
    "import ML_Utils as MU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pretrained Fast_Text Wordvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('supper', 0.8135534524917603), ('dinners', 0.7936621904373169), ('banquet', 0.7714864015579224), ('luncheon', 0.7681770324707031), ('lunch', 0.767798900604248), ('meal', 0.7627254128456116), ('Dinner', 0.7396844625473022), ('breakfast', 0.7091683149337769), ('brunch', 0.6875953674316406), ('meals', 0.6836446523666382)]\n"
     ]
    }
   ],
   "source": [
    "Fast_Text_Model = TPU.Get_Word2Vec_Model('C:\\Sundar\\Project\\Wave_ML_Challenge\\ml-challenge-expenses\\wiki-news-300d-1M.vec')\n",
    "print (Fast_Text_Model.most_similar('dinner'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pretrained Glove Wordvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('dinners', 0.7367478609085083), ('breakfast', 0.7218676805496216), ('lunch', 0.7212514281272888), ('luncheon', 0.6610217094421387), ('guests', 0.6499863266944885), ('banquet', 0.646759033203125), ('meal', 0.6411886215209961), ('brunch', 0.5942021608352661), ('meals', 0.5799444913864136), ('gala', 0.5731527209281921)]\n"
     ]
    }
   ],
   "source": [
    "Glove_Model = TPU. Get_Word2Vec_Model_From_Glove('C:\\Sundar\\Project\\Wave_ML_Challenge\\ml-challenge-expenses\\glove.6B.300d.txt')\n",
    "print (Glove_Model.most_similar('dinner'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Raw data into Predictors and Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Training_Sentences, Training_Labels = DPU.Get_Data('./training_data_example.csv')\n",
    "Validation_Sentances, Validation_Labels = DPU.Get_Data('./validation_data_example.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Features using Wordvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Fast_Text_Training_Features = DPU.Get_Feature_Vectors(Training_Sentences,Fast_Text_Model)\n",
    "Fast_Text_Trial = dict(zip(Training_Sentences,Fast_Text_Training_Features))\n",
    "\n",
    "Glove_Training_Features = DPU.Get_Feature_Vectors(Training_Sentences,Glove_Model)\n",
    "Glove_Trial =  dict(zip(Training_Sentences,Glove_Training_Features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training and Performance (Fast text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Probabilities\n",
      "========================\n",
      "[[ 0.13333333  0.06666667  0.73333333  0.06666667]\n",
      " [ 0.13333333  0.2         0.13333333  0.53333333]\n",
      " [ 0.26666667  0.          0.13333333  0.6       ]\n",
      " [ 0.          0.          1.          0.        ]\n",
      " [ 0.4         0.06666667  0.13333333  0.4       ]\n",
      " [ 0.13333333  0.66666667  0.2         0.        ]]\n",
      "\n",
      "Validation results with Validation dataset\n",
      "==========================================\n",
      "      classifier  train_score  test_score  (1, train_score)\n",
      "0              0          0.0    0.000000               1.0\n",
      "1  Random Forest          NaN    0.833333               1.0\n",
      "\n",
      "Actual class vs predicted class\n",
      "===============================\n",
      "{'Meals and Entertainment': 'Meals and Entertainment', 'Travel': 'Travel', 'Office Supplies': 'Computer - Hardware', 'Computer - Software': 'Computer - Software'}\n"
     ]
    }
   ],
   "source": [
    "Model,Train_Score,X_Test,y_Test = MU.Train_Model(Fast_Text_Training_Features,Training_Labels)\n",
    "results = MU.Validate_Model(Model,X_Test,y_Test)\n",
    "results[1,'train_score'] = Train_Score\n",
    "\n",
    "predicted_class = Model.predict(X_Test)\n",
    "Actual_Vs_Pred = dict(zip(y_Test,predicted_class))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Validation results with Validation dataset\")\n",
    "print(\"==========================================\")\n",
    "print(results)\n",
    "print(\"\")\n",
    "print(\"Actual class vs predicted class\")\n",
    "print(\"===============================\")\n",
    "print(Actual_Vs_Pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Validation and Performance (Fast text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Probabilities\n",
      "========================\n",
      "[[ 0.          0.          0.          1.        ]\n",
      " [ 0.13333333  0.13333333  0.6         0.13333333]\n",
      " [ 0.6         0.2         0.06666667  0.13333333]\n",
      " [ 0.4         0.06666667  0.13333333  0.4       ]\n",
      " [ 0.33333333  0.          0.26666667  0.4       ]\n",
      " [ 0.13333333  0.26666667  0.26666667  0.33333333]\n",
      " [ 0.13333333  0.06666667  0.73333333  0.06666667]\n",
      " [ 0.          0.          1.          0.        ]\n",
      " [ 0.          0.          0.93333333  0.06666667]\n",
      " [ 0.          0.          1.          0.        ]\n",
      " [ 0.          0.          1.          0.        ]\n",
      " [ 0.          0.          1.          0.        ]]\n",
      "\n",
      "Validation results with Validation dataset\n",
      "==========================================\n",
      "      classifier  train_score  test_score  (1, train_score)\n",
      "0              0          0.0    0.000000               1.0\n",
      "1  Random Forest          NaN    0.833333               1.0\n",
      "\n",
      "Actual class vs predicted class\n",
      "===============================\n",
      "{'Travel': 'Travel', 'Meals and Entertainment': 'Meals and Entertainment', 'Computer - Hardware': 'Computer - Hardware', 'Office Supplies': 'Travel'}\n"
     ]
    }
   ],
   "source": [
    "X_Test = DPU.Get_Feature_Vectors(Validation_Sentances,Fast_Text_Model)\n",
    "y_Test = Validation_Labels\n",
    "\n",
    "results = MU.Validate_Model(Model,X_Test,y_Test)\n",
    "results[1,'train_score'] = Train_Score\n",
    "\n",
    "predicted_class = Model.predict(X_Test)\n",
    "Actual_Vs_Pred = dict(zip(y_Test,predicted_class))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Validation results with Validation dataset\")\n",
    "print(\"==========================================\")\n",
    "print(results)\n",
    "print(\"\")\n",
    "print(\"Actual class vs predicted class\")\n",
    "print(\"===============================\")\n",
    "print(Actual_Vs_Pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training and Performance (Glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Probabilities\n",
      "========================\n",
      "[[ 0.13333333  0.06666667  0.53333333  0.26666667]\n",
      " [ 0.26666667  0.13333333  0.2         0.4       ]\n",
      " [ 0.          0.06666667  0.26666667  0.66666667]\n",
      " [ 0.          0.          1.          0.        ]\n",
      " [ 0.33333333  0.06666667  0.33333333  0.26666667]\n",
      " [ 0.06666667  0.8         0.06666667  0.06666667]]\n",
      "\n",
      "Validation results with Validation dataset\n",
      "==========================================\n",
      "      classifier  train_score  test_score  (1, train_score)\n",
      "0              0          0.0    0.000000               1.0\n",
      "1  Random Forest          NaN    0.833333               1.0\n",
      "\n",
      "Actual class vs predicted class\n",
      "===============================\n",
      "{'Meals and Entertainment': 'Meals and Entertainment', 'Travel': 'Travel', 'Office Supplies': 'Computer - Hardware', 'Computer - Software': 'Computer - Software'}\n"
     ]
    }
   ],
   "source": [
    "Glove_Trained_Model,Train_Score,X_Test,y_Test = MU.Train_Model(Glove_Training_Features,Training_Labels)\n",
    "\n",
    "results = MU.Validate_Model(Glove_Trained_Model,X_Test,y_Test)\n",
    "results[1,'train_score'] = Train_Score\n",
    "\n",
    "predicted_class = Glove_Trained_Model.predict(X_Test)\n",
    "Actual_Vs_Pred = dict(zip(y_Test,predicted_class))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Validation results with Validation dataset\")\n",
    "print(\"==========================================\")\n",
    "print(results)\n",
    "print(\"\")\n",
    "print(\"Actual class vs predicted class\")\n",
    "print(\"===============================\")\n",
    "print(Actual_Vs_Pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Validation and Performance (Glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Probabilities\n",
      "========================\n",
      "[[ 0.          0.          0.          1.        ]\n",
      " [ 0.13333333  0.          0.6         0.26666667]\n",
      " [ 0.46666667  0.26666667  0.13333333  0.13333333]\n",
      " [ 0.33333333  0.06666667  0.33333333  0.26666667]\n",
      " [ 0.2         0.          0.53333333  0.26666667]\n",
      " [ 0.          0.2         0.13333333  0.66666667]\n",
      " [ 0.06666667  0.13333333  0.73333333  0.06666667]\n",
      " [ 0.          0.          1.          0.        ]\n",
      " [ 0.          0.          0.86666667  0.13333333]\n",
      " [ 0.          0.          1.          0.        ]\n",
      " [ 0.          0.          1.          0.        ]\n",
      " [ 0.          0.          1.          0.        ]]\n",
      "\n",
      "Validation results with Validation dataset\n",
      "==========================================\n",
      "      classifier  train_score  test_score  (1, train_score)\n",
      "0              0          0.0    0.000000               1.0\n",
      "1  Random Forest          NaN    0.833333               1.0\n",
      "\n",
      "Actual class vs predicted class\n",
      "===============================\n",
      "{'Travel': 'Travel', 'Meals and Entertainment': 'Meals and Entertainment', 'Computer - Hardware': 'Computer - Hardware', 'Office Supplies': 'Meals and Entertainment'}\n"
     ]
    }
   ],
   "source": [
    "X_Test = DPU.Get_Feature_Vectors(Validation_Sentances,Glove_Model)\n",
    "y_Test = Validation_Labels\n",
    "\n",
    "results = MU.Validate_Model(Glove_Trained_Model,X_Test,y_Test)\n",
    "results[1,'train_score'] = Train_Score\n",
    "\n",
    "predicted_class = Glove_Trained_Model.predict(X_Test)\n",
    "Actual_Vs_Pred = dict(zip(y_Test,predicted_class))\n",
    "\n",
    "print(\"\")\n",
    "print(\"Validation results with Validation dataset\")\n",
    "print(\"==========================================\")\n",
    "print(results)\n",
    "print(\"\")\n",
    "print(\"Actual class vs predicted class\")\n",
    "print(\"===============================\")\n",
    "print(Actual_Vs_Pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
