{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumption:\n",
    "#  1. All the files given was generated by 'train_test_split' with pre-defined test_size and random_state already\n",
    "#  2. All personal expenses will have the following keywords in the expense description. Once found, drop the raw.\n",
    "#     [\"personal\", \"family\", \"families]\n",
    "\n",
    "# Load the data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "df_employee_src = pd.read_csv('employee.csv')\n",
    "df_train_src = pd.read_csv('training_data_example.csv')\n",
    "df_test_src = pd.read_csv('validation_data_example.csv')\n",
    "\n",
    "# Merge with employee data\n",
    "df_train = pd.merge(df_train_src, df_employee_src, on='employee id', how='left')\n",
    "df_test = pd.merge(df_test_src, df_employee_src, on='employee id', how='left')\n",
    "\n",
    "# Assumption: All personal expenses will have the following words in the expense description. \n",
    "# [\"personal\", \"family\", \"families], pre-processing for personal/business expense\n",
    "\n",
    "import re\n",
    "def is_personal_expense(string_param):\n",
    "    for desc in string_param.strip().lower().split():\n",
    "        if re.match(r'personal|family|families', desc):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "# Wipe out expense description if personal expense so that the word count doesn't increase.\n",
    "for i in range(df_train.shape[0]):\n",
    "    if is_personal_expense(df_train.iloc[i]['expense description']):\n",
    "        df_train.loc[i, 'expense description'] = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumption: the files given was generated by 'train_test_split' with pre-defined test_size and random_state already\n",
    "X_train = []\n",
    "for i in range(df_train.shape[0]):\n",
    "\tX_train.append(df_train.iloc[i]['expense description'])\n",
    "y_train = np.array(df_train['category'])\n",
    "\n",
    "X_test = []\n",
    "for i in range(df_test.shape[0]):\n",
    "    X_test.append(df_test.iloc[i]['expense description'])\n",
    "y_test = np.array(df_test['category'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Taxi ride',\n",
       " 'Dinner with Family',\n",
       " 'Macbook Air Computer',\n",
       " 'Paper',\n",
       " 'Pens',\n",
       " 'Airplane ticket to Miami',\n",
       " 'Starbucks coffee',\n",
       " 'Dinner',\n",
       " 'Dinner with client',\n",
       " 'Dinner',\n",
       " 'Dinner',\n",
       " 'Dinner']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Basic imports for all chosen algorithms towards different approaches\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn import model_selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC: 0.846154 (0.230769)\n",
      "NB: 0.692308 (0.417799)\n",
      "SGD: 0.884615 (0.210663)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: cross validate each text processing algorithm first to see what might be the best to pick up initially.\n",
    "\n",
    "# cross validate each desired algorithm first to see what might be the best to pick up initially.\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "seed = 7\n",
    "scoring = 'accuracy'\n",
    "kfold = model_selection.KFold(n_splits=13, random_state=seed)\n",
    "models = []\n",
    "text_clf_svc = Pipeline([('vect', TfidfVectorizer()),\n",
    "                         ('clf', OneVsRestClassifier(LinearSVC(class_weight=\"balanced\")))])\n",
    "\n",
    "text_clf_nb = Pipeline([('vect', TfidfVectorizer()),\n",
    "                         ('clf', MultinomialNB()),])\n",
    "\n",
    "text_clf_sgd = Pipeline([('vect', TfidfVectorizer()),\n",
    "                         ('clf', SGDClassifier(max_iter=5)),\n",
    "])\n",
    "\n",
    "models.append(('SVC', text_clf_svc))\n",
    "models.append(('NB', text_clf_nb))\n",
    "models.append(('SGD', text_clf_sgd))\n",
    "\n",
    "# evaluate each algorithm in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since SGDClassifier has higher score, so start with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "# Approach I: SGDClassifier\n",
    "text_clf_sgd = Pipeline([('vect', TfidfVectorizer()),\n",
    "                         ('clf-svm', SGDClassifier(max_iter=5)),\n",
    "])\n",
    "\n",
    "# fit model with training data\n",
    "text_clf_sgd.fit(X_train, y_train)\n",
    "\n",
    "# evaluation on test data\n",
    "pred = text_clf_sgd.predict(X_test)\n",
    "\n",
    "print(np.mean(pred == y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.875\n",
      "{'clf-svm__alpha': 0.1, 'vect__ngram_range': (1, 1), 'vect__use_idf': False}\n"
     ]
    }
   ],
   "source": [
    "# Approach I cont'd\n",
    "# paramater selection\n",
    "parameters_sgd = {'vect__ngram_range': [(1, 1), (1, 2), (2,2)],\n",
    "                  'vect__use_idf': (True, False),\n",
    "                  'clf-svm__alpha': (1e-1, 1e-2, 1e-3, 1e-4),\n",
    "                 }\n",
    "gs_clf_sgd = GridSearchCV(text_clf_sgd, parameters_sgd, n_jobs=2)\n",
    "gs_clf_sgd = gs_clf_sgd.fit(X_train, y_train)\n",
    "\n",
    "print(gs_clf_sgd.best_score_)\n",
    "print(gs_clf_sgd.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "# Approach I cont'd\n",
    "# apply parameters\n",
    "text_clf_sgd = Pipeline([('vect', TfidfVectorizer(ngram_range=(1,1), use_idf=True)),\n",
    "                         ('clf-svm', SGDClassifier(alpha=1e-2, max_iter=5)),\n",
    "])\n",
    "\n",
    "# fit model with training data with improved params\n",
    "text_clf_sgd.fit(X_train, y_train)\n",
    "\n",
    "# evaluation on test data\n",
    "pred = text_clf_sgd.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End of Approach I. *** Not improved after tuning parameter. `best_score_` is 0.875 ***\n",
    "\n",
    "# Beginning of Approach II."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "# Approach II: OneVsRestClassifier & LinearSVC\n",
    "\n",
    "text_clf_svc = Pipeline([('vect', TfidfVectorizer()),\n",
    "                            ('clf-svc', OneVsRestClassifier(LinearSVC(class_weight=\"balanced\")))])\n",
    "\n",
    "# fit model with training data\n",
    "text_clf_svc.fit(X_train, y_train)\n",
    "\n",
    "# evaluation on test data\n",
    "pred = text_clf_svc.predict(X_test)\n",
    "\n",
    "print(np.mean(pred == y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n",
      "{'vect__ngram_range': (1, 1), 'vect__use_idf': True}\n"
     ]
    }
   ],
   "source": [
    "# Approach II cont'd\n",
    "#paramater selection\n",
    "parameters_svc = {'vect__ngram_range': [(1, 1), (1, 2),(2,2)],\n",
    "                   'vect__use_idf': (True, False)\n",
    "                 }\n",
    "gs_clf_svc = GridSearchCV(text_clf_svc, parameters_svc, n_jobs=2)\n",
    "gs_clf_svc = gs_clf_svc.fit(X_train, y_train)\n",
    "print(gs_clf_svc.best_score_)\n",
    "print(gs_clf_svc.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "# Approach II cont'd\n",
    "# apply parameters\n",
    "text_clf_svc = Pipeline([('vect', TfidfVectorizer(ngram_range=(1,1), use_idf=True)),\n",
    "                            ('clf-svc', OneVsRestClassifier(LinearSVC(class_weight=\"balanced\")))])\n",
    "\n",
    "# fit model with training data\n",
    "text_clf_svc.fit(X_train, y_train)\n",
    "\n",
    "# evaluation on test data\n",
    "pred = text_clf_svc.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End of Approach II. *** Has improved after tuning parameter. `best_score_` is 0.833. ***\n",
    "\n",
    "# Beginning of Approach III."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "# Approach III: Naive Bayers\n",
    "\n",
    "text_clf_nb = Pipeline([('vect', TfidfVectorizer()),\n",
    "                         ('clf-nb', MultinomialNB()),])\n",
    "\n",
    "# fit model with training data\n",
    "text_clf_nb = text_clf_nb.fit(X_train, y_train)\n",
    "\n",
    "# evaluation on test data\n",
    "pred = text_clf_nb.predict(X_test)\n",
    "\n",
    "print(np.mean(pred == y_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.875\n",
      "{'clf-nb__alpha': 0.1, 'vect__ngram_range': (1, 1), 'vect__use_idf': True}\n"
     ]
    }
   ],
   "source": [
    "# Approach III cont'd\n",
    "# paramater selection\n",
    "parameters_nb = {'vect__ngram_range': [(1, 1), (1, 2), (2,2)],\n",
    "                  'vect__use_idf': (True, False),\n",
    "                  'clf-nb__alpha': (1e-1, 1e-2, 1e-3, 1e-4),\n",
    "                 }\n",
    "gs_clf_nb = GridSearchCV(text_clf_nb, parameters_nb, n_jobs=2)\n",
    "gs_clf_nb = gs_clf_nb.fit(X_train, y_train)\n",
    "\n",
    "print(gs_clf_nb.best_score_)\n",
    "print(gs_clf_nb.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "# Approach III cont'd\n",
    "# apply parameters\n",
    "text_clf_nb = Pipeline([('vect', TfidfVectorizer(ngram_range=(1,1), use_idf=True)),\n",
    "                         ('clf-nb', MultinomialNB(alpha=1e-1))])\n",
    "\n",
    "# fit model with training data with improved params\n",
    "text_clf_nb.fit(X_train, y_train)\n",
    "\n",
    "# evaluation on test data\n",
    "pred = text_clf_nb.predict(X_test)\n",
    "\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End of Approach III. *** Has improved after tuning parameter. `best_score_` is 0.875. ***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusion:\n",
    "\n",
    "# After examining all three algorithms, They all have accuracy of 0.91666 (after tuning two of them).\n",
    "# Both SGDClassifier and MultinomialNB (after tuning) would be an ideal pick since they have the same \n",
    "# `best_score_` of 0.875.\n",
    "\n",
    "# However, sincee SGDClassifier has better result after cross validation. \n",
    "# I'd pick SGDClassifier algorithm as my first choice to train the model.\n",
    "\n",
    "# Steps can be done further:\n",
    "#   - since this is text processing classificaiton and NLP problem, we can even tune with stop words and stemming.\n",
    "#   - find more text processing classification algorithm and compare them through the same process.\n",
    "#   - try Neural Networks approach using deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
