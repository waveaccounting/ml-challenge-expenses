{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark based Expense Classification \n",
    "\n",
    "This notebook is the launchpad for running the expense classification algorithm built on Spark using pyspark. To run this notebook, following conditions should be satisfied in the end user machine.\n",
    "\n",
    "1. Spark should be installed in the end user machine\n",
    "2. SPARK_HOME Variable should be setup in the .bashrc file\n",
    "\n",
    "## Approach Overview\n",
    "\n",
    "1. Data Ingestion and Extraction, loading a CSV file is straightforward with Spark csv packages.\n",
    "https://github.com/databricks/spark-csv. This package allows us to convert csv files to Spark dataframes. Hence it offers an advantage of dealing with data organized as a native Spark data structure. All the data management utilities are packaged under **Data_to_Spark_Utils.py** file.\n",
    "<br><br>\n",
    "2. Once CSV files are ingested, only 2 columns are retained, the expenses category and the expense description. My approach to solve this problem is to use an NLP based approach. Expense category column provides the labels/ classes, expense description column provides the features.  Features are extracted from the expense descriptions and are used to train a classifier \n",
    "<br><br>\n",
    "3. Next step is to build a machine learning pipeline for the Spark machine learning library. https://spark.apache.org/docs/2.2.0/ml-pipeline.html. Pipeline construction, data preparation, model specification, training and validation functions are present in the **ML_Utils.py** file. For this exercise, we consider the following: <bbr> \n",
    "    1. regexTokenizer: Tokenization (with Regular Expression)\n",
    "    2. stopwordsRemover: Remove Stop Words\n",
    "    3. countVectors: Count vectors (“document-term vectors”)\n",
    "    4. TF - IDF Features\n",
    "<br><br>\n",
    " 4. The features are used to construct a pipeline. Once the pipeline is constructed, the raw data is given to the pipeline to extract features and labels. This then is passed to classifiers.\n",
    "<br><br>\n",
    " 5. For this exercise, Logistic regression, Logistic regression with cross validation and random forests are implemented. \n",
    "<br><br>\n",
    " 6. The evaluation metrics generated by the multiclass evaluators in Spark help in judging the performance of the models. \n",
    "<br><br>\n",
    "    \n",
    "## Directions to run Algorithm for other files\n",
    "Just change the training and the validation file paths in the second executable cell. The Notebook will take care of the rest. \n",
    "\n",
    "## Key Observations\n",
    "\n",
    "1. The data we use is limited and hence using TF-IDF and other features built here does not represent the classess better. Hence the performance across models are poor\n",
    "<br><br>\n",
    "2. In Python, implementation, I have used word embeddings to perform classification. The results are far superior, as the word embeddings allow us to construct sentance vectors.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import relevant packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To find Spark home and initialize Spark instance to work with Jupyter\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "# Import pyspark to work with Saprk from Python IDE\n",
    "import pyspark\n",
    "import random\n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext\n",
    "\n",
    "# User defined utilities\n",
    "import Data_to_Spark_Utils as D2S\n",
    "import ML_Utils as MU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Spark Context and Ingest CSV as Spark dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc =SparkContext()\n",
    "Training_Data = D2S.Ingest_CSV_in_Spark(sc,\"/home/muthusundaram/Python_trials/Wave_ML_Challenge/training_data_example.csv\" )\n",
    "Validation_Data = D2S.Ingest_CSV_in_Spark(sc,\"/home/muthusundaram/Python_trials/Wave_ML_Challenge/validation_data_example.csv\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benefits of using Dataframes with SQL like interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['date',\n",
       " 'category',\n",
       " 'employee id',\n",
       " 'expense description',\n",
       " 'pre-tax amount',\n",
       " 'tax name',\n",
       " 'tax amount']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Training_Data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|            category| expense description|\n",
      "+--------------------+--------------------+\n",
      "|              Travel|           Taxi ride|\n",
      "|Meals and Enterta...|  Dinner with Family|\n",
      "| Computer - Hardware|Macbook Air Computer|\n",
      "|     Office Supplies|               Paper|\n",
      "|     Office Supplies|                Pens|\n",
      "|              Travel|Airplane ticket t...|\n",
      "|Meals and Enterta...|    Starbucks coffee|\n",
      "|Meals and Enterta...|              Dinner|\n",
      "|Meals and Enterta...|  Dinner with client|\n",
      "|Meals and Enterta...|              Dinner|\n",
      "|Meals and Enterta...|              Dinner|\n",
      "|Meals and Enterta...|              Dinner|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "drop_list = ['date','employee id', 'pre-tax amount', 'tax name',  'tax amount']\n",
    "Training_Data = D2S.Drop_Coulmns_from_DataFrame(Training_Data,drop_list)\n",
    "Validation_Data = D2S.Drop_Coulmns_from_DataFrame(Validation_Data,drop_list)\n",
    "Validation_Data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- category: string (nullable = true)\n",
      " |-- expense description: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Training_Data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- category: string (nullable = true)\n",
      " |-- expense description: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Validation_Data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            Category|count|\n",
      "+--------------------+-----+\n",
      "|Meals and Enterta...|   10|\n",
      "|              Travel|    6|\n",
      "| Computer - Software|    4|\n",
      "| Computer - Hardware|    3|\n",
      "|     Office Supplies|    1|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "Training_Data.groupBy(\"Category\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "| expense description|count|\n",
      "+--------------------+-----+\n",
      "|              Dinner|    4|\n",
      "|           Taxi ride|    3|\n",
      "|Airplane ticket t...|    2|\n",
      "|Dropbox Subscription|    2|\n",
      "|  Dinner with client|    1|\n",
      "|     Flight to Miami|    1|\n",
      "|              iPhone|    1|\n",
      "| iCloud Subscription|    1|\n",
      "|          Team lunch|    1|\n",
      "|    Microsoft Office|    1|\n",
      "|  HP Laptop Computer|    1|\n",
      "|   Coffee with Steve|    1|\n",
      "|               Paper|    1|\n",
      "|Dinner with poten...|    1|\n",
      "|       Client dinner|    1|\n",
      "|Macbook Air Computer|    1|\n",
      "|    Starbucks coffee|    1|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Training_Data.groupBy(\"expense description\") \\\n",
    "    .count() \\\n",
    "    .orderBy(col(\"count\").desc()) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct machine learning pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from pyspark.ml import Pipeline\n",
    "pipeline = MU.Construct_Pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed Raw data to Pipeline for Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Engineer the features based on constructed pipeline for both training and validation set\n",
    "Training_Dataset = MU.Construct_ML_Dataset(pipeline,Training_Data)\n",
    "Validation_Dataset = MU.Construct_ML_Dataset(pipeline,Validation_Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 16\n",
      "Test Dataset Count: 8\n",
      "Training Dataset Count: 16\n",
      "Test Dataset Count: 8\n",
      "Training Dataset Count: 16\n",
      "Test Dataset Count: 8\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic regression model\n",
    "LR_Model, LR_Test_Data = MU.Train_Model(Training_Dataset, \"LR\")\n",
    "\n",
    "# Train Logistis regression model with cross validation\n",
    "LRCV_Model, LRCV_Test_Data = MU.Train_Model(Training_Dataset, \"LRCV\")\n",
    "\n",
    "# Train Random Forest model\n",
    "RF_Model, RF_Test_Data = MU.Train_Model(Training_Dataset, \"RF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate and Publish Performance Metrics (both for test/ hold out data and validation data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-----------------------+------------------------------+-----+----------+\n",
      "|  expense description|               category|                   probability|label|prediction|\n",
      "+---------------------+-----------------------+------------------------------+-----+----------+\n",
      "|        Client dinner|Meals and Entertainment|[0.674359311290608,0.095459...|  0.0|       0.0|\n",
      "|               Dinner|Meals and Entertainment|[0.674359311290608,0.095459...|  0.0|       0.0|\n",
      "| Dropbox Subscription|    Computer - Software|[0.23892761729025916,0.2293...|  2.0|       0.0|\n",
      "|    Coffee with Steve|Meals and Entertainment|[0.23892761729025916,0.2293...|  0.0|       0.0|\n",
      "|Airplane ticket to NY|                 Travel|[0.23892761729025916,0.2293...|  1.0|       0.0|\n",
      "|            Taxi ride|                 Travel|[0.23892761729025916,0.2293...|  1.0|       0.0|\n",
      "|     Starbucks coffee|Meals and Entertainment|[0.23892761729025916,0.2293...|  0.0|       0.0|\n",
      "|Airplane ticket to NY|                 Travel|[0.23892761729025916,0.2293...|  1.0|       0.0|\n",
      "+---------------------+-----------------------+------------------------------+-----+----------+\n",
      "\n",
      "Summary Stats\n",
      "F(1) Score         = 0.3333333333333333\n",
      "Weighted Precision = 0.25\n",
      "Weighted Recall    = 0.5\n",
      "Accuracy           = 0.5\n"
     ]
    }
   ],
   "source": [
    "evaluator,predictions  = MU.Validate_Model(LR_Model,LR_Test_Data)\n",
    "\n",
    "print(\"Summary Stats\")\n",
    "print(\"F(1) Score         = %s\" % evaluator.evaluate(predictions,{evaluator.metricName: \"f1\"}))\n",
    "print(\"Weighted Precision = %s\" % evaluator.evaluate(predictions,{evaluator.metricName: \"weightedPrecision\"}))\n",
    "print(\"Weighted Recall    = %s\" % evaluator.evaluate(predictions,{evaluator.metricName: \"weightedRecall\"}))\n",
    "print(\"Accuracy           = %s\" % evaluator.evaluate(predictions,{evaluator.metricName: \"accuracy\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+-----------------------+------------------------------+-----+----------+\n",
      "|     expense description|               category|                   probability|label|prediction|\n",
      "+------------------------+-----------------------+------------------------------+-----+----------+\n",
      "|      Dinner with Family|Meals and Entertainment|[0.4668343323157805,0.15839...|  0.0|       0.0|\n",
      "|      Dinner with client|Meals and Entertainment|[0.4668343323157805,0.15839...|  0.0|       0.0|\n",
      "|                  Dinner|Meals and Entertainment|[0.4668343323157805,0.15839...|  0.0|       0.0|\n",
      "|                  Dinner|Meals and Entertainment|[0.4668343323157805,0.15839...|  0.0|       0.0|\n",
      "|                  Dinner|Meals and Entertainment|[0.4668343323157805,0.15839...|  0.0|       0.0|\n",
      "|                  Dinner|Meals and Entertainment|[0.4668343323157805,0.15839...|  0.0|       0.0|\n",
      "|               Taxi ride|                 Travel|[0.23892761729025916,0.2293...|  1.0|       0.0|\n",
      "|    Macbook Air Computer|    Computer - Hardware|[0.23892761729025916,0.2293...|  3.0|       0.0|\n",
      "|        Starbucks coffee|Meals and Entertainment|[0.23892761729025916,0.2293...|  0.0|       0.0|\n",
      "|                   Paper|        Office Supplies|[0.23892761729025916,0.2293...|  2.0|       0.0|\n",
      "|                    Pens|        Office Supplies|[0.23892761729025916,0.2293...|  2.0|       0.0|\n",
      "|Airplane ticket to Miami|                 Travel|[0.23892761729025916,0.2293...|  1.0|       0.0|\n",
      "+------------------------+-----------------------+------------------------------+-----+----------+\n",
      "\n",
      "Summary Stats\n",
      "F(1) Score         = 0.4298245614035088\n",
      "Weighted Precision = 0.34027777777777785\n",
      "Weighted Recall    = 0.5833333333333334\n",
      "Accuracy           = 0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "evaluator,predictions = MU.Validate_Model(LR_Model,Validation_Dataset)\n",
    "\n",
    "print(\"Summary Stats\")\n",
    "print(\"F(1) Score         = %s\" % evaluator.evaluate(predictions,{evaluator.metricName: \"f1\"}))\n",
    "print(\"Weighted Precision = %s\" % evaluator.evaluate(predictions,{evaluator.metricName: \"weightedPrecision\"}))\n",
    "print(\"Weighted Recall    = %s\" % evaluator.evaluate(predictions,{evaluator.metricName: \"weightedRecall\"}))\n",
    "print(\"Accuracy           = %s\" % evaluator.evaluate(predictions,{evaluator.metricName: \"accuracy\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------------------+------------------------------+-----+----------+\n",
      "|expense description|               category|                   probability|label|prediction|\n",
      "+-------------------+-----------------------+------------------------------+-----+----------+\n",
      "|      Client dinner|Meals and Entertainment|[0.8213359733256489,0.05153...|  0.0|       0.0|\n",
      "|             Dinner|Meals and Entertainment|[0.8213359733256489,0.05153...|  0.0|       0.0|\n",
      "+-------------------+-----------------------+------------------------------+-----+----------+\n",
      "\n",
      "Summary Stats\n",
      "F(1) Score         = 0.369047619047619\n",
      "Weighted Precision = 0.5208333333333334\n",
      "Weighted Recall    = 0.375\n",
      "Accuracy           = 0.375\n"
     ]
    }
   ],
   "source": [
    "evaluator,predictions = MU.Validate_Model(LRCV_Model,LRCV_Test_Data)\n",
    "\n",
    "print(\"Summary Stats\")\n",
    "print(\"F(1) Score         = %s\" % evaluator.evaluate(predictions,{evaluator.metricName: \"f1\"}))\n",
    "print(\"Weighted Precision = %s\" % evaluator.evaluate(predictions,{evaluator.metricName: \"weightedPrecision\"}))\n",
    "print(\"Weighted Recall    = %s\" % evaluator.evaluate(predictions,{evaluator.metricName: \"weightedRecall\"}))\n",
    "print(\"Accuracy           = %s\" % evaluator.evaluate(predictions,{evaluator.metricName: \"accuracy\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------------------+------------------------------+-----+----------+\n",
      "|expense description|               category|                   probability|label|prediction|\n",
      "+-------------------+-----------------------+------------------------------+-----+----------+\n",
      "| Dinner with Family|Meals and Entertainment|[0.528261292898544,0.139022...|  0.0|       0.0|\n",
      "|             Dinner|Meals and Entertainment|[0.528261292898544,0.139022...|  0.0|       0.0|\n",
      "| Dinner with client|Meals and Entertainment|[0.528261292898544,0.139022...|  0.0|       0.0|\n",
      "|             Dinner|Meals and Entertainment|[0.528261292898544,0.139022...|  0.0|       0.0|\n",
      "|             Dinner|Meals and Entertainment|[0.528261292898544,0.139022...|  0.0|       0.0|\n",
      "|             Dinner|Meals and Entertainment|[0.528261292898544,0.139022...|  0.0|       0.0|\n",
      "+-------------------+-----------------------+------------------------------+-----+----------+\n",
      "\n",
      "Summary Stats\n",
      "F(1) Score         = 0.6217948717948718\n",
      "Weighted Precision = 0.638888888888889\n",
      "Weighted Recall    = 0.6666666666666666\n",
      "Accuracy           = 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "evaluator,predictions = MU.Validate_Model(LRCV_Model,Validation_Dataset)\n",
    "\n",
    "print(\"Summary Stats\")\n",
    "print(\"F(1) Score         = %s\" % evaluator.evaluate(predictions,{evaluator.metricName: \"f1\"}))\n",
    "print(\"Weighted Precision = %s\" % evaluator.evaluate(predictions,{evaluator.metricName: \"weightedPrecision\"}))\n",
    "print(\"Weighted Recall    = %s\" % evaluator.evaluate(predictions,{evaluator.metricName: \"weightedRecall\"}))\n",
    "print(\"Accuracy           = %s\" % evaluator.evaluate(predictions,{evaluator.metricName: \"accuracy\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-----------------------+------------------------------+-----+----------+\n",
      "|  expense description|               category|                   probability|label|prediction|\n",
      "+---------------------+-----------------------+------------------------------+-----+----------+\n",
      "|        Client dinner|Meals and Entertainment|[0.385303005846474,0.181004...|  0.0|       0.0|\n",
      "|               Dinner|Meals and Entertainment|[0.385303005846474,0.181004...|  0.0|       0.0|\n",
      "| Dropbox Subscription|    Computer - Software|[0.3576406681841363,0.19050...|  2.0|       0.0|\n",
      "|    Coffee with Steve|Meals and Entertainment|[0.3576406681841363,0.19050...|  0.0|       0.0|\n",
      "|Airplane ticket to NY|                 Travel|[0.3576406681841363,0.19050...|  1.0|       0.0|\n",
      "|            Taxi ride|                 Travel|[0.3576406681841363,0.19050...|  1.0|       0.0|\n",
      "|     Starbucks coffee|Meals and Entertainment|[0.3576406681841363,0.19050...|  0.0|       0.0|\n",
      "|Airplane ticket to NY|                 Travel|[0.3576406681841363,0.19050...|  1.0|       0.0|\n",
      "+---------------------+-----------------------+------------------------------+-----+----------+\n",
      "\n",
      "Summary Stats\n",
      "F(1) Score         = 0.3333333333333333\n",
      "Weighted Precision = 0.25\n",
      "Weighted Recall    = 0.5\n",
      "Accuracy           = 0.5\n"
     ]
    }
   ],
   "source": [
    "evaluator,predictions = MU.Validate_Model(RF_Model,RF_Test_Data)\n",
    "\n",
    "print(\"Summary Stats\")\n",
    "print(\"F(1) Score         = %s\" % evaluator.evaluate(predictions,{evaluator.metricName: \"f1\"}))\n",
    "print(\"Weighted Precision = %s\" % evaluator.evaluate(predictions,{evaluator.metricName: \"weightedPrecision\"}))\n",
    "print(\"Weighted Recall    = %s\" % evaluator.evaluate(predictions,{evaluator.metricName: \"weightedRecall\"}))\n",
    "print(\"Accuracy           = %s\" % evaluator.evaluate(predictions,{evaluator.metricName: \"accuracy\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+-----------------------+------------------------------+-----+----------+\n",
      "|     expense description|               category|                   probability|label|prediction|\n",
      "+------------------------+-----------------------+------------------------------+-----+----------+\n",
      "|      Dinner with Family|Meals and Entertainment|[0.385303005846474,0.181004...|  0.0|       0.0|\n",
      "|      Dinner with client|Meals and Entertainment|[0.385303005846474,0.181004...|  0.0|       0.0|\n",
      "|                  Dinner|Meals and Entertainment|[0.385303005846474,0.181004...|  0.0|       0.0|\n",
      "|                  Dinner|Meals and Entertainment|[0.385303005846474,0.181004...|  0.0|       0.0|\n",
      "|                  Dinner|Meals and Entertainment|[0.385303005846474,0.181004...|  0.0|       0.0|\n",
      "|                  Dinner|Meals and Entertainment|[0.385303005846474,0.181004...|  0.0|       0.0|\n",
      "|               Taxi ride|                 Travel|[0.3576406681841363,0.19050...|  1.0|       0.0|\n",
      "|    Macbook Air Computer|    Computer - Hardware|[0.3576406681841363,0.19050...|  3.0|       0.0|\n",
      "|        Starbucks coffee|Meals and Entertainment|[0.3576406681841363,0.19050...|  0.0|       0.0|\n",
      "|                   Paper|        Office Supplies|[0.3576406681841363,0.19050...|  2.0|       0.0|\n",
      "|                    Pens|        Office Supplies|[0.3576406681841363,0.19050...|  2.0|       0.0|\n",
      "|Airplane ticket to Miami|                 Travel|[0.3576406681841363,0.19050...|  1.0|       0.0|\n",
      "+------------------------+-----------------------+------------------------------+-----+----------+\n",
      "\n",
      "Summary Stats\n",
      "F(1) Score         = 0.4298245614035088\n",
      "Weighted Precision = 0.34027777777777785\n",
      "Weighted Recall    = 0.5833333333333334\n",
      "Accuracy           = 0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "evaluator,predictions = MU.Validate_Model(RF_Model,Validation_Dataset)\n",
    "\n",
    "print(\"Summary Stats\")\n",
    "print(\"F(1) Score         = %s\" % evaluator.evaluate(predictions,{evaluator.metricName: \"f1\"}))\n",
    "print(\"Weighted Precision = %s\" % evaluator.evaluate(predictions,{evaluator.metricName: \"weightedPrecision\"}))\n",
    "print(\"Weighted Recall    = %s\" % evaluator.evaluate(predictions,{evaluator.metricName: \"weightedRecall\"}))\n",
    "print(\"Accuracy           = %s\" % evaluator.evaluate(predictions,{evaluator.metricName: \"accuracy\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
